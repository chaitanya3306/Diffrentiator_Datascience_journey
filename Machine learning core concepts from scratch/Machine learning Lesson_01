{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1iDUg6p9Aakj5VIJSR9xiQySB9K4PXWLv\" width=640 /></center>\n",
        "<br/>\n",
        "\n",
        "<font size=6>\n",
        "<center>Lesson 1: Introduction to Machine Learning\n",
        "</center>\n",
        "</font>\n",
        "\n",
        "<font size=4>\n",
        "<center><i>A crash-course on every hype of AI technology</i>\n",
        "</center>\n",
        "</font>"
      ],
      "metadata": {
        "id": "Bcfx5yMxZays"
      },
      "id": "Bcfx5yMxZays"
    },
    {
      "cell_type": "markdown",
      "id": "6345005e",
      "metadata": {
        "id": "6345005e"
      },
      "source": [
        "# 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3eafcd5",
      "metadata": {
        "id": "b3eafcd5"
      },
      "source": [
        "## About This Course"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This course is about **Machine Learning** – often just called “ML” for short. But before we demystify ML, let’s start by talking about _what it can do_. Why learn about it at all? As it turns out, ML is the underlying technology behind many things in our lives: it gives us music recommendations, creates beautiful images and texts (well, it tries), and it’s even being used to help find cures for different diseases ([example](https://deepmind.google/discover/blog/stopping-malaria-in-its-tracks/)).\n",
        "\n",
        "ML is also worth learning about because it is now a critical component for many businesses and, beyond all this – it’s just plain interesting to work with! So, if this all sounds like a promising path for you, you’ve found the right course to help you start down this road."
      ],
      "metadata": {
        "id": "kaRjWjJHlKe3"
      },
      "id": "kaRjWjJHlKe3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Course Overview"
      ],
      "metadata": {
        "id": "J0ke9TmT54lL"
      },
      "id": "J0ke9TmT54lL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 5 lessons in this course, including this introduction. In each lesson (starting from the next), we’ll guide you through solving some non-trivial problem using ML, all while explaining all the necessary theory. In these lessons you will:\n",
        "\n",
        "* Learn about the **current** **state of ML** and how it’s evolving\n",
        "* Understand what you need to make ML work and the **tasks it can solve**\n",
        "* **Practice implementing ML** systems in code\n",
        "\n",
        "And of course, along the way, we’ll also play with generative models like ChatGPT!\n",
        "\n",
        "Here’s an overview of the lesson contents:"
      ],
      "metadata": {
        "id": "v1h2dt5smw5P"
      },
      "id": "v1h2dt5smw5P"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1Vw_cx4ECpYWtI2sP_ai62P8STQ_ig4nD\" width=1000 /></center>"
      ],
      "metadata": {
        "id": "t6ByNXQOokiK"
      },
      "id": "t6ByNXQOokiK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "_Disclaimer: While you’ll definitely learn a lot here by writing code and creating models, it probably won’t be enough to score a job. But, if you decide to continue your ML studies, we invite you to our [Practical Generative AI course](https://ai-dt.school/generative-ai/)._"
      ],
      "metadata": {
        "id": "Fvzmerqgnax-"
      },
      "id": "Fvzmerqgnax-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What to Expect"
      ],
      "metadata": {
        "id": "0qQyIgks574F"
      },
      "id": "0qQyIgks574F"
    },
    {
      "cell_type": "markdown",
      "id": "ba81f49e",
      "metadata": {
        "id": "ba81f49e"
      },
      "source": [
        "The lessons are made up of Jupyter notebooks with **theory** and **code**. Some of that code will be missing, and you’ll need to fill it in to make the notebook work. Then, after you’ve written your solution, go ahead and look at the notebooks with solutions (we will add links to them in the following lessons). Inside, you’ll find keys for all the missing pieces of code. (You can also just look at these if you get stuck, but we encourage you to really try and solve all the problems on your own first).\n",
        "\n",
        "This course is intended for learners of all different levels, and that means that you’ll sometimes encounter some rather complex **math explanations**. That said, these are not critical for this course, and you can feel free to skip them. In any case, these will also be accompanied by simplified summaries to convey the general idea."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This Lesson Overview"
      ],
      "metadata": {
        "id": "RJ7PY-Dmoydn"
      },
      "id": "RJ7PY-Dmoydn"
    },
    {
      "cell_type": "markdown",
      "id": "3a4528cd",
      "metadata": {
        "id": "3a4528cd"
      },
      "source": [
        "In this lesson we’ll introduce machine learning in two sections:\n",
        "\n",
        "* In section 2, we’ll explain machine learning and give a wide overview of what it can be\n",
        "* In section 3, we’ll take an example problem and look closely at how machine learning can solve it\n",
        "\n",
        "This lesson doesn’t feature any code, just theory – and with that, let’s jump in."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. What is Machine Learning"
      ],
      "metadata": {
        "id": "qqVFOeszo4OD"
      },
      "id": "qqVFOeszo4OD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To kick things off, let’s tackle an essential question."
      ],
      "metadata": {
        "id": "BYyygn0vny6U"
      },
      "id": "BYyygn0vny6U"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why do we need machine learning?"
      ],
      "metadata": {
        "id": "CojXED80kPhv"
      },
      "id": "CojXED80kPhv"
    },
    {
      "cell_type": "markdown",
      "id": "4146f933",
      "metadata": {
        "id": "4146f933"
      },
      "source": [
        "So, why even bother with machine learning? It all boils down to algorithms, and ML gives us a way of developing algorithms, most often for some task that we want to solve using software, but we **don't know how to directly implement the solution**.\n",
        "\n",
        "For example, let’s say we want to build an app that translates text from one language to another. At present, the exact algorithm to do this remains unknown – as a matter of fact, many linguists have worked on this problem but haven't managed to achieve the near-human level of translation provided by modern ML-based translators (though this research certainly helped with the development of ML-based methods).\n",
        "\n",
        "Now, operating within the ML paradigm, we can **solve this problem indirectly** by developing an algorithm that will create an algorithm _for us_. If that sounds even more complex, consider this metaphor: when building skyscrapers, people simply cannot lift some of the materials by hand, right? So, we build machines to do the physical heavy lifting for us. In terms of software, we’re making the machines do the \"informational heavy-lifting”.\n",
        "\n",
        "One crucial component when using machine learning is the **training data**. This is a collection of data related to the task, and the ML algorithm pulls the knowledge for creating the solution algorithm from this data.\n",
        "\n",
        "For example, to revisit the case of machine translation, the training data could be a collection of texts that were previously translated manually by human translators. Now, it’s worth noting that collecting this data is not always the easiest thing in the world, but it turns out that sometimes this is easier than trying to manually implement the algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1FLh1ael2CDZYBLwRAK8rL02L2TUXdNE0\" width=320 />\n",
        "</center>"
      ],
      "metadata": {
        "id": "buxUcYLPmGNq"
      },
      "id": "buxUcYLPmGNq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, to sum things up: ML developers design **algorithms that process training data and output new algorithms**. Then, these new algorithms are embedded into software (most often alongside with other algorithms) to solve the task at large.\n",
        "\n",
        "Now that we have a basic understanding of the machine learning paradigm, let's learn what ML models can look like in general. We’re not aiming to give a full overview of ML, we just want to highlight the most popular areas of application and show how diverse the field can be."
      ],
      "metadata": {
        "id": "Ktq0oDjcmGY0"
      },
      "id": "Ktq0oDjcmGY0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supervised Learning"
      ],
      "metadata": {
        "id": "oQcIcNVmoeb2"
      },
      "id": "oQcIcNVmoeb2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's start with **supervised learning** tasks (and machine translation is actually one of these).\n",
        "\n",
        "Supervised learning tasks require an **object** and a **target**. The object can be essentially anything digital, while the target is something connected to this object that we ultimately want to predict.\n",
        "\n",
        "Here are some examples to help make this clear:"
      ],
      "metadata": {
        "id": "f5ZONizwohLH"
      },
      "id": "f5ZONizwohLH"
    },
    {
      "cell_type": "markdown",
      "id": "5de3e9ca",
      "metadata": {
        "id": "5de3e9ca"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1oNcqKtC-8Lzn_3r1UPpQjG90Ar7HkHIA\" width=540 />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The important characteristic of supervised learning tasks worth highlighting is that for every object there is an expected correct answer (and sometimes more than one, although that is not important), and we want a model that will be able to predict targets as close to this answer as possible.\n",
        "\n",
        "In order to train these kinds of models, we need **labeled** data – for each data point (object) there must be a correct answer (target) provided, also called **ground truth**.\n",
        "\n",
        "While training, the model tries to infer the algorithm that will take objects as inputs and output the proper targets. After that, when put into production, the algorithm will predict targets for new data points.\n",
        "\n",
        "For another example of a supervised learning model, let's consider a self-driving vehicle that has pedestrian detection as one of its sub-systems. Let’s organize this in terms of supervised learning\n",
        "\n",
        "\n",
        "\n",
        "* Each object is an image from the front camera (we will avoid considering other sensors for simplicity’s sake).\n",
        "* The target is a list of coordinates and the sizes of any pedestrians in the image. (Usually represented as a list of boxes.)\n",
        "* The training data is a set of real street photos where boxes have been manually drawn by human labelers around the pedestrians.\n",
        "\n",
        "And using data like this, a machine learning model will be able to detect pedestrians using just raw photos."
      ],
      "metadata": {
        "id": "FGew5Lxqosrj"
      },
      "id": "FGew5Lxqosrj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1OtdrwkShhIDwGPtwAOUjEoVkFIKXGuiw\" width=600 />\n",
        "\n",
        "*Image from [JAAD dataset](https://data.nvision2.eecs.yorku.ca/JAAD_dataset/)*\n",
        "</center>"
      ],
      "metadata": {
        "id": "muT6jXJF5DcN"
      },
      "id": "muT6jXJF5DcN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generative Tasks"
      ],
      "metadata": {
        "id": "EPVxm28ipXCs"
      },
      "id": "EPVxm28ipXCs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "That was a more straightforward case, but sometimes our target is more ambiguous. For example, there are many correct answers to this question: \"What do you see in this picture?\" One might answer “a cat”, “a laptop”, “a city” – there are numerous responses that are ultimately correct in their own right."
      ],
      "metadata": {
        "id": "U_zQ53zyo5cM"
      },
      "id": "U_zQ53zyo5cM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1duwq9usLDLqLBWZXkTurKpe2Yjvnz0Us\" width=256 />\n",
        "</center>"
      ],
      "metadata": {
        "id": "aAQ10CTSpIq6"
      },
      "id": "aAQ10CTSpIq6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "And if we ask a more broad question, \"Please describe what you see in the picture\", there could be even more options: \"A cat with a laptop\", \"A cyberpunk cat\", \"A cat with a city in the background\" and so on.\n",
        "\n",
        "In this case, we don't want the model to give some specific correct answer, we just want it to **generate** an answer that is reasonable, but this can be quite variable as well.\n",
        "\n",
        "These tasks are referred to as **generative** and, in this case, we want the model to learn the **distribution** of the data and then give us reasonable samples using it.\n",
        "\n",
        "Here are some examples of generative tasks:"
      ],
      "metadata": {
        "id": "bwmlQ_PIpNou"
      },
      "id": "bwmlQ_PIpNou"
    },
    {
      "cell_type": "markdown",
      "id": "f0fb8b60",
      "metadata": {
        "id": "f0fb8b60"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=17ZfWpf5xhDoni383IueJ8fsyug-PrcYK\" width=700 />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These tasks can be useful on their own, or they can be a part of a more complex model. We'll discuss generative tasks further in one of the following lessons."
      ],
      "metadata": {
        "id": "ViqSBkggpRs0"
      },
      "id": "ViqSBkggpRs0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self-Supervised Learning"
      ],
      "metadata": {
        "id": "4YogNxcvphiB"
      },
      "id": "4YogNxcvphiB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In machine learning, usually the more complex the model you want to create, the more data you need. However, if it's a supervised learning task, acquiring large amounts of labeled data may be too expensive.\n",
        "\n",
        "For example, if we want to create a ChatGPT model this way, we would need billions of questions with good-quality answers – which is essentially impossible to get.\n",
        "\n",
        "For tasks like that, it would be good to have some basic model that \"understands\" the domain in general, which we can then combine with something else to solve our task.\n",
        "\n",
        "If we linger on the question of chat models a bit more, it would be great to have a model that generally understands \"how to use language\": grammar, combining phrases into reasonable statements, logical reasoning, and so on.\n",
        "\n",
        "These models are often called **foundational models**, and they are rather hard to train, but can be used in a range of different applications.\n",
        "\n",
        "So how do we get data for that kind of model? One way is to take unlabeled data and create a new synthetic task that transforms this unlabeled data into labeled data.\n",
        "\n",
        "For example if we’re working with large amounts of random texts, we can scan them word-by-word and try to predict the next word by using all the words that were seen before. This becomes a supervised learning task, where objects are a list of words before a given word and targets are single words (following the corresponding prefixes). These following words usually can't be predicted with a high level of certainty, so the model is expected to simply learn which options are more probable, and which are less. And actually this task requires the model to have knowledge of grammar, sentence structure and logical reasoning that we discussed earlier."
      ],
      "metadata": {
        "id": "l7dzNSn3pa8v"
      },
      "id": "l7dzNSn3pa8v"
    },
    {
      "cell_type": "markdown",
      "id": "61a567f1",
      "metadata": {
        "id": "61a567f1"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1ZRqsGHIAdJ5qJYe7P4rrBQAfbM0yjrRr\" width=450 />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This approach is called **self-supervised learning**, and it can be applied to many areas.\n",
        "\n",
        "For example, with videos, we can take a sequence of frames and try to predict the next one; with images we can remove some pixels (or even larger patches) and try to predict what should go there using all the other parts of the image.\n",
        "\n",
        "All in all, this is a very powerful method of learning because it can use large, unlabeled amounts of data. We’ll talk about how it can be incorporated into more complex models in one of the following sections."
      ],
      "metadata": {
        "id": "07Esuq7lpfsr"
      },
      "id": "07Esuq7lpfsr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reinforcement Learning"
      ],
      "metadata": {
        "id": "E01--2rSpk8z"
      },
      "id": "E01--2rSpk8z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some models don't work with the regular data at all. For instance, this is the case with the **reinforcement learning** approach, which gets data in a more interactive way:\n",
        "\n",
        "* With this approach there is some kind of environment, for example, a video game.\n",
        "* Models can interact with this environment: get inputs (also called **state** of the environment) and perform **actions**. In case of a video game, inputs could be frame-by-frame screenshots, and actions might be the game controls.\n",
        "* During these interactions, the models receive special numeric values called **rewards** (and also punishments, which are just negative rewards). For a video game, they may get a small reward for picking up an in-game item, a big reward for winning the game, and a big punishment for losing.\n",
        "* The model plays the game repeatedly trying to \"beat the game\" – that is, to develop an algorithm that will maximize its average reward."
      ],
      "metadata": {
        "id": "ZItrD6Xspo34"
      },
      "id": "ZItrD6Xspo34"
    },
    {
      "cell_type": "markdown",
      "id": "eaa2db9d",
      "metadata": {
        "id": "eaa2db9d"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1jztLehN4_EeXLGOY-AjoHlO9cycCCKbF\" width=350 />\n",
        "\n",
        "*Image from [Atari 2600 Pacman game](https://en.wikipedia.org/wiki/Pac-Man_(Atari_2600_video_game))*\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These methods are usually capable of achieving very _interesting_ results (for example, beating all the top Go players. At the same time, they are quite difficult to set up and train."
      ],
      "metadata": {
        "id": "kueGvYBepvYC"
      },
      "id": "kueGvYBepvYC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Large Language Models"
      ],
      "metadata": {
        "id": "JpfUq-aepoRW"
      },
      "id": "JpfUq-aepoRW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we want to devote a separate section to large language models (LLMs) because of how important they are in the current AI landscape. These models combine several approaches ,for example, ChatGPT was trained in several stages:\n",
        "\n",
        "* The GPT core model was trained in a self-supervised way. This gives the model a general understanding of how languages and texts work. At this stage, the model already has lots of useful knowledge, but has not been specifically trained to follow instructions; it also doesn’t yet know how to filter potentially harmful content.\n",
        "* Next, the developers trained the model to follow instructions; performing alignment training to prevent the generation of harmful answers also occurs at this stage. There are two stages of training here:\n",
        "    * First, the model was trained in a supervised way using examples of humans answering instructions. For this, the developers collected a dataset of prompts with detailed professional answers.\n",
        "    * Then, the model was trained answering new instructions, but this time, instead of seeing the correct answers, special moderators looked through the dialogues and evaluated the quality of the answers. After, those evaluations were used as rewards and punishments, and the model was trained in a reinforcement learning paradigm.\n",
        "\n",
        "Multi-stage approaches like this are becoming more common and are usually necessary for models that aim to solve hard problems, utilizing as much data as possible. Those models are usually themselves quite big in order to be able to pull as much knowledge from the data as possible.\n",
        "\n",
        "To conclude this, let's just ask ChatGPT to explain how large language models are trained:"
      ],
      "metadata": {
        "id": "_nzV7-HAvtZE"
      },
      "id": "_nzV7-HAvtZE"
    },
    {
      "cell_type": "markdown",
      "id": "eed36043",
      "metadata": {
        "id": "eed36043"
      },
      "source": [
        "\n",
        "**🤖 ChatGPT:**\n",
        "\n",
        "<blockquote><p>\n",
        "Large language models are created through a two-step process: training and fine-tuning. In the training phase, the models are exposed to massive amounts of text data from the internet, books, articles, and more. They learn by predicting the next word in a sentence based on the context provided by the previous words. This helps them understand grammar, meaning, and relationships between words.\n",
        "    \n",
        "Once the initial training is complete, the models undergo fine-tuning. During this phase, they are exposed to more specific and carefully curated datasets to improve their performance in specific tasks or domains. This fine-tuning process allows the models to specialize in areas like translation, summarization, or even medical diagnosis, depending on the training data used.\n",
        "\n",
        "    \n",
        "Both training and fine-tuning involve complex algorithms running on powerful computers with vast amounts of computational resources. The resulting models can then be used to interact with humans, providing assistance, generating text, or helping in various language-related tasks.\n",
        "</p></blockquote>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1xyUZWlXJq3NqLDuTFZkwFfHvQiUtmSIM\" width=320 />\n",
        "</center>"
      ],
      "metadata": {
        "id": "_IHN-NzWo0eH"
      },
      "id": "_IHN-NzWo0eH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Example: Text Classification"
      ],
      "metadata": {
        "id": "1i9Qv4E3ptBe"
      },
      "id": "1i9Qv4E3ptBe"
    },
    {
      "cell_type": "markdown",
      "id": "744a6008",
      "metadata": {
        "id": "744a6008"
      },
      "source": [
        "Now that we have an overview of what ML can do, to help us understand a little more how algorithms work, let's pick an example problem and look at it more closely.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task Description"
      ],
      "metadata": {
        "id": "0Ie88uR5pvaD"
      },
      "id": "0Ie88uR5pvaD"
    },
    {
      "cell_type": "markdown",
      "id": "f036a255",
      "metadata": {
        "id": "f036a255"
      },
      "source": [
        "Let's imagine that we’re developing a website where users can share and discuss the stories they’ve written. The database is very big with lots of different data, and we want to add automatic genre recognition, in order to simplify the search and navigation.\n",
        "\n",
        "So, essentially, we have texts looking like this (generated with ChatGPT):\n",
        "\n",
        "<blockquote><p>\n",
        "The starship Orion cruised through the vast expanse of space, its engines humming smoothly as it navigated through the swirling clouds of cosmic dust. Captain Rachel Ward stood on the bridge, gazing out at the endless stars through the viewport. She had been leading the Orion on its mission of exploration for years now, and she had come to love the solitude and the sense of purpose that came with the job.\n",
        "</p></blockquote>\n",
        "\n",
        "Our question, which genre does this text belong with, sci-fi, fantasy or horror?\n",
        "\n",
        "\n",
        "\n",
        "This task is a supervised learning problem and, more specifically, a **text classification** problem. This is because we have a set of **classes**, and we need to assign them to the texts.\n",
        "\n",
        "For simplicity, let's reduce this to just one genre problem: for a given text, we just want to determine if it’s sci-fi or not. This is called a **binary classification** problem because we need to decide between two classes: \"sci-fi\" and \"not sci-fi\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Direct Approach vs The ML-based Approach"
      ],
      "metadata": {
        "id": "lloFxANipyEK"
      },
      "id": "lloFxANipyEK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1yE08vhlEbJzgGk4AwEl1GXY5L_e9No2B\" width=320 /></center>"
      ],
      "metadata": {
        "id": "yW3545gMqbCQ"
      },
      "id": "yW3545gMqbCQ"
    },
    {
      "cell_type": "markdown",
      "id": "91579ac8",
      "metadata": {
        "id": "91579ac8"
      },
      "source": [
        "To get a hold on the problem as a whole, let’s first start with a direct implementation approach that does not involve ML. We’ll write a bunch of rules using our general knowledge:\n",
        "\n",
        "\n",
        "\n",
        "* Words like \"spaceship\" or \"android\" are most likely from sci-fi\n",
        "* If we see the words \"wizard\" or \"magic\", the text probably belongs to the fantasy category, and we can put the text into \"not sci-fi\" category\n",
        "* ... and we can conceive a ton of similar rules.\n",
        "\n",
        "This will probably give us an _adequate-ish_ system with just a couple of hours of work. Naturally, the question follows: is this _good enough_? We need some kind of criterion to measure the **classification quality** of our program.\n",
        "\n",
        "And we can indeed measure it by using some labeled data – just manually picking some texts and deciding the most likely genre. With this data, we can pass it through our program and count the percentage of correct answers. This measure is called **accuracy**, and we want it to be as high as possible.\n",
        "\n",
        "However, simple, hand-crafted rules will probably have low accuracy. Sure, perhaps if we work on them long enough, we’ll end up with decent accuracy, but there are many tasks where this brute-force approach simply doesn't work (as with the machine translation example we mentioned earlier). Let's learn how to solve this with machine learning.\n",
        "\n",
        "If we want to solve this using ML, we want to create an algorithm that will look through training data, notice patterns between texts and their genres, and deduce rules using it (this is actually very similar to how humans learn to do it). So the next question is: how exactly does the machine learn those rules from training data? Setting up the algorithms to do this is exactly what ML jobs are about. Let's learn about one simple way to do this."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Algorithm"
      ],
      "metadata": {
        "id": "VzOCEHgWp1It"
      },
      "id": "VzOCEHgWp1It"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want the machine learning algorithm to create a classification program (or **classifier** for short). Let's first decide how it can look. One simple way is to imitate what we did in the hand-crafted rules approach:\n",
        "\n",
        "* Let’s say we have a **dictionary** of words important for genre identification (\"spaceship\" or \"wizard\").\n",
        "* Each word has its own **score**, which shows if the word is more likely within the sci-fi genre or not. For example, the word \"starship\" might have a score of +0.5 and the word wizard could have a score of -0.7\n",
        "* The classifier searches through the text for the words from the dictionary and totals all the scores it found.\n",
        "* If the final score is positive, it declares that the answer is \"sci-fi\", and if it is negative it says \"not sci-fi\"."
      ],
      "metadata": {
        "id": "tE8Jjo-Fwgfd"
      },
      "id": "tE8Jjo-Fwgfd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1vCpg9ZQIt6MsjzQ0JADCYL_w3uHrK6He\" width=500 />\n",
        "</center>"
      ],
      "metadata": {
        "id": "Lq3cABBPwnly"
      },
      "id": "Lq3cABBPwnly"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that, at the moment, we have neither the dictionary nor the scores – we just decided how our classifier will look in general. We’ll deal with acquiring those values later.\n",
        "\n",
        "Also, let’s point out that the algorithm is quite simple and it is already easy to see some possible problems (no matter how good the dictionary and scores), because it ignores the context of the words completely. An interesting thing is that this level of algorithm can still be considerably better than hand-crafted rules. But in any case, we’re going to improve it later, and this algorithm is sufficient for explaining all the basics."
      ],
      "metadata": {
        "id": "RfX9dm1wwpN2"
      },
      "id": "RfX9dm1wwpN2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "    <summary><font color=\"404090\">An example when this algorithm can fail (click to expand).</font></summary>\n",
        "    \n",
        "In a sci-fi story, one character compliments another character's skill by calling her a \"wizard\":\n",
        "    \n",
        "<blockquote>\n",
        "\n",
        "Captain Rourke observed Lieutenant Thompson as she effortlessly manipulated the complex holographic interface, her fingers dancing across the virtual controls with a grace that bordered on the supernatural. He marveled at her uncanny ability to navigate the intricate systems of their advanced starship, her expertise unparalleled.\n",
        "\n",
        "\"Thompson,\" he called out, admiration evident in his voice. \"You're a **wizard** with these systems, you know that?\"\n",
        "\n",
        "Thompson turned to face him, a grin spreading across her face. \"Captain, you flatter me,\" she replied, her eyes twinkling with a mix of amusement and pride. \"But it's not **magic**, just years of practice and a deep understanding of the technology.\"</blockquote>\n",
        "    \n",
        "In response to the appearance of this “fantasy” term within this text, the algorithm may react as if it reduces the possibility of this text being sci-fi, which is obviously incorrect.\n",
        "\n",
        "<br/>\n",
        "</details>"
      ],
      "metadata": {
        "id": "YX-nrd3ewsEG"
      },
      "id": "YX-nrd3ewsEG"
    },
    {
      "cell_type": "markdown",
      "id": "be69b538",
      "metadata": {
        "id": "be69b538"
      },
      "source": [
        "Now we have a **model** – this is like the “concept” of how our algorithm will work, without defining the actual scores and dictionary, and also without thinking yet about how to get them. It is typical for ML models to be defined in this way: we first outline the algorithm, leaving some gaps (here dictionary and scores), and then we figure out how to fill them in using training data; these gaps are called the **parameters** of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Linear Classifier"
      ],
      "metadata": {
        "id": "p2s80C5yp56N"
      },
      "id": "p2s80C5yp56N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we want to transform how our model looks because we want to be able to apply math algorithms to find all the missing parts. What we'll get in the end is called a **linear classifier**.\n",
        "\n",
        "Let's focus on the list of important words and their scores (we’ll put in some arbitrary values for this example):"
      ],
      "metadata": {
        "id": "t1LyyUENxIZy"
      },
      "id": "t1LyyUENxIZy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "| word | score |\n",
        "|---|---|\n",
        "| starship | 0.5 |\n",
        "| cosmic | 0.3 |\n",
        "| wizard | -0.7 |\n",
        "| dragon | -0.6 |\n",
        "| ... | ... |"
      ],
      "metadata": {
        "id": "_OKdjoJwxLKU"
      },
      "id": "_OKdjoJwxLKU"
    },
    {
      "cell_type": "markdown",
      "id": "f3700df7",
      "metadata": {
        "id": "f3700df7"
      },
      "source": [
        "\n",
        "\n",
        "Using this table, we can write the output of the classifier as a formula. To do so, let's define some variables:\n",
        "\n",
        "* The variable for _starship_ is 1.0 if this word is present in the text and 0.0 if it is not\n",
        "* The same applies for _cosmic_, _wizard_ and all the other words in the dictionary\n",
        "* The variable _score_ is the final score of the classifier (prediction);\n",
        "* _pred_ is the prediction of the classifier (True if the text belongs to sci-fi and False otherwise).\n",
        "\n",
        "Then, we get:\n",
        "\n",
        "```Python\n",
        "score = 0.5 * starship + 0.3 * cosmic - 0.7 * wizard - 0.6 * dragon + ...\n",
        "pred = score > 0\n",
        "```\n",
        "\n",
        "_Note: we are assuming that an exact zero score is rare, and we don't care what the answer is in that case._"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That is the formula for our specific example, we now need to make it more abstract. Let's create new variables for that:\n",
        "\n",
        "- $x_1, x_2, \\ldots, x_N$ – variables for words, where $N$ is the size of the dictionary. If $i$-th word from the dictionary is present in the given text, we get $x_i = 1$ and otherwise we get $x_i = 0$. These are the input variables, and they are also called **features** of the objects, it is common to use letter $x$ for those.\n",
        "\n",
        "- $s$ — variable for the output score.\n",
        "\n",
        "- $\\color{magenta}{w_1}, \\color{magenta}{w_2}, \\dots, \\color{magenta}{w_N}$ — scores assigned to the specific words, also using $N$ — the size of the dictionary. The letter $w$ comes from the word **weights**, which is a common notation for some parameters that are inside a formula (we are also highlighting the parameters in formulas with magenta for easier reading). Those are the values we will later acquire from the training data.\n",
        "\n",
        "Now we can write:\n",
        "\n",
        "$$\n",
        "s = \\color{magenta}{w_1} x_1 + \\color{magenta}{w_2} x_2 + \\ldots + \\color{magenta}{w_N} x_N\n",
        "$$\n",
        "\n",
        "That's it – this is the **linear classifier**, which has this name because the function  $s(x_1, x_2, \\ldots, x_N)$ is linear."
      ],
      "metadata": {
        "id": "zS50OcUXjHR6"
      },
      "id": "zS50OcUXjHR6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "6KjtEIxtqNz_"
      },
      "id": "6KjtEIxtqNz_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's finally talk about how to get the dictionary and the values of the weights. The process of getting them out of training data is called **training** or **learning**.\n",
        "\n",
        "We’re only going to briefly outline it now, but we’ll give a detailed explanation in the next lesson.\n",
        "\n",
        "First, to get the dictionary, a simple trick is usually used. Let's look through the training data and create a dictionary of _all_ the possible words from it (for simplicity let's assume we have some kind of tool that matches different forms of the same word). This may sound strange because obviously not all words are important, but the importance can actually be reflected by the weights. A word can be in the dictionary, but at the same time can have a weight close to 0 – this will mean it is not very important. So, we’ve just basically reduced two problems to one – we only need to understand how to acquire weights now.\n",
        "\n",
        "And at this point, let's get to the harder part – getting the weights. The training algorithm combines several components:\n",
        "\n",
        "\n",
        "* First, it needs a formula that takes features and weights as input and outputs the scores. We already have it from before – this is our linear classifier formula.\n",
        "* It plugs all the training data into this formula and gets the scores for all the examples from it. For now let's just assume that we use random values for weights. Remember that we also have the correct answers already prepared.\n",
        "* We know that we want our model to have high _accuracy_, or a low percentage of errors. Let's plug the model's predictions together with the correct answers into the accuracy formula and get the error percentage. In the real training algorithm, instead of accuracy, another measure is used, but it’s  quite close in terms of meaning, so we won't go into this for now. But, in the next lesson we will, and we’ll also explain why just using the accuracy doesn't work well.\n",
        "* So, we get a list of error values for all the training examples. We then average them all to get one final error value for our dataset."
      ],
      "metadata": {
        "id": "Wdw1xa2uyMVp"
      },
      "id": "Wdw1xa2uyMVp"
    },
    {
      "cell_type": "markdown",
      "id": "eaaea09a",
      "metadata": {
        "id": "eaaea09a"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1kbZ1GoUlbQgjp2u3UOfLIHKp80TwY0Ka\" width=800 />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By doing all this, we get a single value that reflects how good the model is and that is directly connected to the model weights. Basically, it’s a function that takes weights and outputs their overall error. That is a very good result – that’s because now we can just apply some mathematical optimization methods. These take functions and find the inputs that minimize the output of the function (not always perfect in practice, but that doesn't matter just now). We’ll dive deeper into these types of algorithms in the next lesson.\n",
        "\n",
        "For now, this is it, the algorithm is ready. After training it using optimization methods, we get a model, inside of which is a formula with learned weights. The next step is to measure its accuracy, and if it is good enough, ship it into production. As this is a theoretical problem, we can't actually test the model, but in the next lesson, we will do all this in practice."
      ],
      "metadata": {
        "id": "x4Ebg9rfyW-C"
      },
      "id": "x4Ebg9rfyW-C"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Conclusion"
      ],
      "metadata": {
        "id": "p04Lgg0LqcWf"
      },
      "id": "p04Lgg0LqcWf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's recap what we learned in this lesson.\n",
        "\n",
        "In the overview section, we talked about machine learning models in general and learned that ML software works differently from regular algorithms: instead of implementing the logic directly, we implement an algorithm that learns the logic from training data.\n",
        "\n",
        "This training data can come in different forms: it can be labeled (suitable for supervised learning) or unlabeled (suitable for self-supervised learning), and can even come in the form of interactive environments with rewards and penalties (reinforcement learning).\n",
        "\n",
        "We also learned that many modern models require large amounts of data to train, and they are frequently composed of different stages (as with ChatGPT):"
      ],
      "metadata": {
        "id": "dbxPzk5-ynfC"
      },
      "id": "dbxPzk5-ynfC"
    },
    {
      "cell_type": "markdown",
      "id": "3a5deb18",
      "metadata": {
        "id": "3a5deb18"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1ZvSDaCBvKi6wQnEC9kKFGAjgARCpqWbt\" width=800 />\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the model example section, we went deeper into one specific problem and learned the steps necessary for designing a ML model:\n",
        "\n",
        "* We defined what is the problem we want to solve and what is the training data for it. We also decided how to understand how good the model is (model quality).\n",
        "* We designed a machine learning model: we defined the features it has and how it converts them into predictions. We also defined the parameters of the model – the weights that we can change to tune the model to the data.\n",
        "* We then rewrote the model as a formula and developed a training algorithm that uses formula optimization to find the best weights."
      ],
      "metadata": {
        "id": "b81hB73JyybI"
      },
      "id": "b81hB73JyybI"
    },
    {
      "cell_type": "markdown",
      "id": "3253b3a2",
      "metadata": {
        "id": "3253b3a2"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1j2uCVIAs2uM5uzVf7vso6LrYIb7lHrAf\" width=500 />\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! In the [**next lesson**](https://colab.research.google.com/github/Nebius-Academy/ML-Starter-Pack/blob/main/notebooks/lesson_2.ipynb) you will learn how to **train linear models** with Python and go even further into all the related math.\n",
        "\n",
        "Additionally, if you’re interested, here are some additional resources on the things we talked about in this lesson:\n",
        "\n",
        "* [A visualisation of the data distribution for a simple generative task: handwritten digits](https://n8python.github.io/mnistLatentSpace/)\n",
        "* [Reinforcement Learning example video: AI learns to solve simple puzzles](https://www.youtube.com/watch?v=v3UBlEJDXR0)\n",
        "* [Blogpost about training ChatGPT from OpenAI](https://openai.com/blog/chatgpt)"
      ],
      "metadata": {
        "id": "gmeHOzNny5zi"
      },
      "id": "gmeHOzNny5zi"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QGhU5_W2kerq"
      },
      "id": "QGhU5_W2kerq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}